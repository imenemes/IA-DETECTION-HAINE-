{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled1.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyNgZDgfBP/By1bUU1+mtADc"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "## 8- **EMT**"
      ],
      "metadata": {
        "id": "ybbKBol7Cmda"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NC5JlNsXb0Dl",
        "outputId": "5ab2ab45-c242-47c3-898e-ab68cc17b189"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "clean_data= '/content/drive/MyDrive/Colab Notebooks/clean_dataset_oversample'\n",
        "with open(clean_data, \"r\") as file:\n",
        "    lines = file.readlines()\n",
        "    \n",
        "clean_full = [line.split() for line in lines]"
      ],
      "metadata": {
        "id": "R5qyxGfMcJVl"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import random\n",
        "random.seed(3)\n",
        "#on travaille avec un échantillon de 100000 tweets\n",
        "clean_sample = random.sample(clean_full, 100000)\n",
        "print(len(clean_sample))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zkICBfcacRwv",
        "outputId": "f151dbe3-cefb-48ce-93e2-76bfa3670b40"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "100000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "cleaned_tweet= list(clean_sample)\n",
        "\n",
        "for i in range(len(cleaned_tweet)):\n",
        "    cleaned_tweet[i] = ' '.join(cleaned_tweet[i])"
      ],
      "metadata": {
        "id": "9jwhQZapuimV"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**ETM's original article:**\n",
        "\n",
        "@article {dieng2019topic,\n",
        "\n",
        "    title = {Topic modeling in embedding spaces},\n",
        "\n",
        "    author = {Dieng, Adji B and Ruiz, Francisco J R and Blei, David M},\n",
        "\n",
        "    journal = {arXiv preprint arXiv: 1907.04907},\n",
        "\n",
        "    year = {2019}\n",
        "}\n"
      ],
      "metadata": {
        "id": "uElZpuAcF0MF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -U embedded_topic_model"
      ],
      "metadata": {
        "id": "tnBXDEKECdHl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from embedded_topic_model.utils import preprocessing\n",
        "\n",
        "# Preprocessing the dataset\n",
        "vocabulary, train_dataset, _, = preprocessing.create_etm_datasets(\n",
        "    cleaned_tweet, \n",
        "    min_df=0.01, \n",
        "    max_df=0.75, \n",
        "    train_size=0.85, \n",
        ")"
      ],
      "metadata": {
        "id": "1CPHiD4oED93"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#cela a pris 6min35 sur mon PC\n",
        "%%time\n",
        "from embedded_topic_model.utils import embedding\n",
        "\n",
        "# Training word2vec embeddings\n",
        "embeddings_mapping = embedding.create_word2vec_embedding_from_dataset(cleaned_tweet)"
      ],
      "metadata": {
        "id": "oY9VTDoVEwA9"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "a- **Méthode 1 : avec les embeddings entrainés sur nos données**"
      ],
      "metadata": {
        "id": "3YAqiQ5SFItN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "from embedded_topic_model.models.etm import ETM\n",
        "# Training an ETM instance\n",
        "etm_instance = ETM(\n",
        "    vocabulary,\n",
        "    embeddings=embeddings_mapping, # You can pass here the path to a word2vec file or\n",
        "                                   # a KeyedVectors instance\n",
        "    num_topics=8,\n",
        "    epochs=15,\n",
        "    debug_mode=True,\n",
        "    train_embeddings=False, # Optional. If True, ETM will learn word embeddings jointly with\n",
        "                            # topic embeddings. By default, is False. If 'embeddings' argument\n",
        "                            # is being passed, this argument must not be True\n",
        ")\n",
        "\n",
        "etm_instance.fit(train_dataset)"
      ],
      "metadata": {
        "id": "1dfWAeXvE9M7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ddf19081-d708-4190-ceb7-f5756fc4a314"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Topics before training: [['vouloir', 'femme', 'mal', 'venir', 'pouvoir', 'grand', 'croire', 'jour', 'vie', 'gros'], ['temps', 'bien', 'mettre', 'faire', 'jour', 'passer', 'monde', 'france', 'grand', 'aime'], ['sale', 'monde', 'taire', 'français', 'croire', 'gros', 'passer', 'jour', 'grand', 'aller'], ['aime', 'passer', 'croire', 'taire', 'monde', 'vouloir', 'grand', 'petit', 'fils', 'temps'], ['croire', 'gros', 'vouloir', 'savoir', 'venir', 'devoir', 'bien', 'jour', 'grand', 'an'], ['pute', 'taire', 'france', 'savoir', 'femme', 'chose', 'vouloir', 'fils', 'mettre', 'pouvoir'], ['temps', 'voir', 'passer', 'monde', 'mettre', 'sale', 'femme', 'aime', 'fils', 'pute'], ['temps', 'pute', 'gros', 'petit', 'venir', 'femme', 'jour', 'vrai', 'mal', 'aime']]\n",
            "Epoch 1 - Learning Rate: 0.005 - KL theta: 0.07 - Rec loss: 5.86 - NELBO: 5.93\n",
            "Epoch 2 - Learning Rate: 0.005 - KL theta: 0.0 - Rec loss: 5.82 - NELBO: 5.82\n",
            "Epoch 3 - Learning Rate: 0.005 - KL theta: 0.0 - Rec loss: 5.82 - NELBO: 5.82\n",
            "Epoch 4 - Learning Rate: 0.005 - KL theta: 0.01 - Rec loss: 5.8 - NELBO: 5.81\n",
            "Epoch 5 - Learning Rate: 0.005 - KL theta: 0.01 - Rec loss: 5.81 - NELBO: 5.82\n",
            "Epoch 6 - Learning Rate: 0.005 - KL theta: 0.02 - Rec loss: 5.79 - NELBO: 5.81\n",
            "Epoch 7 - Learning Rate: 0.005 - KL theta: 0.03 - Rec loss: 5.78 - NELBO: 5.81\n",
            "Epoch 8 - Learning Rate: 0.005 - KL theta: 0.05 - Rec loss: 5.76 - NELBO: 5.81\n",
            "Epoch 9 - Learning Rate: 0.005 - KL theta: 0.06 - Rec loss: 5.76 - NELBO: 5.82\n",
            "Epoch 10 - Learning Rate: 0.005 - KL theta: 0.07 - Rec loss: 5.74 - NELBO: 5.81\n",
            "Topics: [['pute', 'sale', 'gros', 'fils', 'aller', 'faire', 'femme', 'bien', 'voir', 'pouvoir'], ['faire', 'aller', 'pouvoir', 'bien', 'vouloir', 'falloir', 'voir', 'femme', 'devoir', 'temps'], ['faire', 'aller', 'voir', 'devoir', 'bien', 'pouvoir', 'savoir', 'vouloir', 'venir', 'prendre'], ['faire', 'aller', 'voir', 'savoir', 'bien', 'vouloir', 'petit', 'femme', 'pouvoir', 'falloir'], ['france', 'faire', 'français', 'an', 'grand', 'pouvoir', 'mettre', 'bien', 'aller', 'vouloir'], ['faire', 'aller', 'bien', 'voir', 'pouvoir', 'falloir', 'vouloir', 'savoir', 'passer', 'monde'], ['faire', 'aller', 'pouvoir', 'femme', 'voir', 'vie', 'vouloir', 'bien', 'an', 'savoir'], ['aller', 'faire', 'voir', 'bien', 'pouvoir', 'savoir', 'prendre', 'femme', 'vouloir', 'falloir']]\n",
            "Epoch 11 - Learning Rate: 0.005 - KL theta: 0.08 - Rec loss: 5.73 - NELBO: 5.81\n",
            "Epoch 12 - Learning Rate: 0.005 - KL theta: 0.09 - Rec loss: 5.71 - NELBO: 5.8\n",
            "Epoch 13 - Learning Rate: 0.005 - KL theta: 0.1 - Rec loss: 5.71 - NELBO: 5.81\n",
            "Epoch 14 - Learning Rate: 0.005 - KL theta: 0.1 - Rec loss: 5.69 - NELBO: 5.79\n",
            "CPU times: user 47.3 s, sys: 531 ms, total: 47.8 s\n",
            "Wall time: 47.7 s\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "topics = etm_instance.get_topics(20)\n",
        "topic_coherence = etm_instance.get_topic_coherence()\n",
        "topic_diversity = etm_instance.get_topic_diversity()"
      ],
      "metadata": {
        "id": "3k6r_eXXMhSF"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for i in range(8): print(topics[i])"
      ],
      "metadata": {
        "id": "8cl-YP7TMsd9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d61f8f1a-64e6-4930-c74c-28b115868f8c"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['sale', 'pute', 'gros', 'fils', 'aller', 'faire', 'bien', 'petit', 'voir', 'mettre', 'vouloir', 'aime', 'grand', 'taire', 'pouvoir', 'vie', 'vrai', 'femme', 'venir', 'savoir']\n",
            "['faire', 'aller', 'bien', 'pouvoir', 'prendre', 'monde', 'savoir', 'taire', 'vouloir', 'falloir', 'devoir', 'voir', 'petit', 'mal', 'femme', 'jour', 'grand', 'mettre', 'passer', 'chose']\n",
            "['faire', 'aller', 'pouvoir', 'voir', 'venir', 'devoir', 'bien', 'vouloir', 'falloir', 'savoir', 'monde', 'mettre', 'jour', 'chose', 'vrai', 'croire', 'prendre', 'passer', 'taire', 'grand']\n",
            "['faire', 'aller', 'pouvoir', 'voir', 'bien', 'savoir', 'vouloir', 'falloir', 'devoir', 'temps', 'passer', 'monde', 'venir', 'jour', 'mettre', 'vrai', 'prendre', 'femme', 'mal', 'croire']\n",
            "['français', 'france', 'an', 'grand', 'faire', 'jour', 'pouvoir', 'vouloir', 'devoir', 'aller', 'bien', 'vie', 'mettre', 'passer', 'savoir', 'falloir', 'femme', 'monde', 'petit', 'venir']\n",
            "['faire', 'aller', 'bien', 'voir', 'pouvoir', 'vouloir', 'falloir', 'passer', 'temps', 'croire', 'monde', 'jour', 'savoir', 'mettre', 'vrai', 'mal', 'devoir', 'chose', 'venir', 'prendre']\n",
            "['femme', 'faire', 'aller', 'vie', 'pouvoir', 'savoir', 'prendre', 'aime', 'bien', 'voir', 'petit', 'vouloir', 'taire', 'mal', 'falloir', 'mettre', 'devoir', 'monde', 'vrai', 'croire']\n",
            "['faire', 'aller', 'bien', 'voir', 'pouvoir', 'falloir', 'savoir', 'croire', 'vouloir', 'prendre', 'venir', 'mettre', 'jour', 'monde', 'temps', 'passer', 'petit', 'sale', 'grand', 'taire']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(topic_coherence)"
      ],
      "metadata": {
        "id": "_hp1wmSTQW_g",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ae5954c5-07e5-4b16-8403-fb5a5b3508d6"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "-0.03221466331640218\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(topic_diversity)"
      ],
      "metadata": {
        "id": "4-4msek0QbuZ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ce3c32c3-dd4d-4d09-a8d6-18753820330e"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.165\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "b- **Méthode 2 : avec les embeddings pré-entrainés**"
      ],
      "metadata": {
        "id": "CQnNFnClFY6o"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Training an ETM instance\n",
        "etm_instance = ETM(\n",
        "    vocabulary,\n",
        "    embeddings= '/content/drive/MyDrive/Colab Notebooks/frwiki_20180420_100d.txt', # You can pass here the path to a word2vec file or\n",
        "                                   # a KeyedVectors instance\n",
        "    num_topics=8,\n",
        "    epochs=20,\n",
        "    debug_mode=True,\n",
        "    train_embeddings=True, # Optional. If True, ETM will learn word embeddings jointly with\n",
        "                            # topic embeddings. By default, is False. If 'embeddings' argument\n",
        "                            # is being passed, this argument must not be True\n",
        ")\n",
        "\n",
        "etm_instance.fit(train_dataset)"
      ],
      "metadata": {
        "id": "gKEaAduDFp_I",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "64b8fccf-ad75-48ae-af63-6be9d1fd3c0e"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Topics before training: [['aller', 'femme', 'jour', 'voir', 'gros', 'vrai', 'sale', 'bien', 'fils', 'grand'], ['jour', 'sale', 'temps', 'bien', 'chose', 'grand', 'pouvoir', 'pute', 'vrai', 'voir'], ['monde', 'devoir', 'vie', 'français', 'prendre', 'mettre', 'vouloir', 'grand', 'taire', 'aime'], ['croire', 'pouvoir', 'petit', 'jour', 'aller', 'voir', 'gros', 'chose', 'faire', 'mal'], ['falloir', 'savoir', 'gros', 'france', 'aller', 'grand', 'taire', 'prendre', 'passer', 'devoir'], ['passer', 'mettre', 'grand', 'vrai', 'savoir', 'devoir', 'petit', 'faire', 'sale', 'jour'], ['voir', 'devoir', 'pute', 'croire', 'femme', 'gros', 'petit', 'passer', 'france', 'chose'], ['france', 'passer', 'gros', 'mettre', 'devoir', 'faire', 'venir', 'petit', 'temps', 'jour']]\n",
            "Epoch 1 - Learning Rate: 0.005 - KL theta: 0.07 - Rec loss: 5.89 - NELBO: 5.96\n",
            "Epoch 2 - Learning Rate: 0.005 - KL theta: 0.0 - Rec loss: 5.81 - NELBO: 5.81\n",
            "Epoch 3 - Learning Rate: 0.005 - KL theta: 0.0 - Rec loss: 5.82 - NELBO: 5.82\n",
            "Epoch 4 - Learning Rate: 0.005 - KL theta: 0.0 - Rec loss: 5.82 - NELBO: 5.82\n",
            "Epoch 5 - Learning Rate: 0.005 - KL theta: 0.0 - Rec loss: 5.81 - NELBO: 5.81\n",
            "Epoch 6 - Learning Rate: 0.005 - KL theta: 0.0 - Rec loss: 5.82 - NELBO: 5.82\n",
            "Epoch 7 - Learning Rate: 0.005 - KL theta: 0.01 - Rec loss: 5.81 - NELBO: 5.82\n",
            "Epoch 8 - Learning Rate: 0.005 - KL theta: 0.01 - Rec loss: 5.81 - NELBO: 5.82\n",
            "Epoch 9 - Learning Rate: 0.005 - KL theta: 0.0 - Rec loss: 5.81 - NELBO: 5.81\n",
            "Epoch 10 - Learning Rate: 0.005 - KL theta: 0.01 - Rec loss: 5.8 - NELBO: 5.81\n",
            "Topics: [['faire', 'aller', 'voir', 'bien', 'pouvoir', 'sale', 'femme', 'falloir', 'vouloir', 'savoir'], ['faire', 'aller', 'pouvoir', 'voir', 'bien', 'sale', 'vouloir', 'falloir', 'femme', 'savoir'], ['faire', 'aller', 'voir', 'bien', 'pouvoir', 'sale', 'vouloir', 'femme', 'devoir', 'falloir'], ['faire', 'aller', 'voir', 'pouvoir', 'bien', 'sale', 'vouloir', 'falloir', 'femme', 'savoir'], ['faire', 'aller', 'pouvoir', 'voir', 'bien', 'vouloir', 'savoir', 'sale', 'devoir', 'femme'], ['faire', 'aller', 'bien', 'voir', 'pouvoir', 'sale', 'femme', 'falloir', 'vouloir', 'devoir'], ['faire', 'aller', 'voir', 'pouvoir', 'bien', 'vouloir', 'savoir', 'devoir', 'sale', 'femme'], ['pute', 'fils', 'gros', 'france', 'français', 'petit', 'faire', 'aller', 'monde', 'mettre']]\n",
            "Epoch 11 - Learning Rate: 0.005 - KL theta: 0.03 - Rec loss: 5.79 - NELBO: 5.82\n",
            "Epoch 12 - Learning Rate: 0.005 - KL theta: 0.04 - Rec loss: 5.78 - NELBO: 5.82\n",
            "Epoch 13 - Learning Rate: 0.005 - KL theta: 0.04 - Rec loss: 5.77 - NELBO: 5.81\n",
            "Epoch 14 - Learning Rate: 0.005 - KL theta: 0.04 - Rec loss: 5.76 - NELBO: 5.8\n",
            "Epoch 15 - Learning Rate: 0.005 - KL theta: 0.05 - Rec loss: 5.75 - NELBO: 5.8\n",
            "Epoch 16 - Learning Rate: 0.005 - KL theta: 0.05 - Rec loss: 5.76 - NELBO: 5.81\n",
            "Epoch 17 - Learning Rate: 0.005 - KL theta: 0.05 - Rec loss: 5.76 - NELBO: 5.81\n",
            "Epoch 18 - Learning Rate: 0.005 - KL theta: 0.05 - Rec loss: 5.75 - NELBO: 5.8\n",
            "Epoch 19 - Learning Rate: 0.005 - KL theta: 0.05 - Rec loss: 5.75 - NELBO: 5.8\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<embedded_topic_model.models.etm.ETM at 0x7f3ff783c5d0>"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Remarque , je n'ai pas pu entrainer ce modèle sans mettre l'argument train_embedding (argument optionnel) à True , ce qui semble contredire ce qui est mentionné dans leur commentaire , à moins que j'ai mal compris ??\n",
        "\n",
        "voici l'erreur que j'ai eue :  unpickling stack underflow "
      ],
      "metadata": {
        "id": "ckUkGCpSVU4a"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "topics = etm_instance.get_topics(20)\n",
        "topic_coherence = etm_instance.get_topic_coherence()\n",
        "topic_diversity = etm_instance.get_topic_diversity()"
      ],
      "metadata": {
        "id": "vS5Vffw8SfRy"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for i in range(8): print(topics[i])"
      ],
      "metadata": {
        "id": "tXH6VzxSSp_S",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4174a7c3-e804-4b10-b22b-1ffa7b92d2cf"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['faire', 'aller', 'pouvoir', 'bien', 'voir', 'falloir', 'femme', 'savoir', 'vouloir', 'devoir', 'jour', 'france', 'monde', 'mettre', 'sale', 'an', 'grand', 'prendre', 'passer', 'vie']\n",
            "['faire', 'aller', 'pouvoir', 'voir', 'bien', 'falloir', 'savoir', 'femme', 'vouloir', 'devoir', 'france', 'jour', 'mettre', 'sale', 'an', 'prendre', 'grand', 'vie', 'français', 'monde']\n",
            "['faire', 'aller', 'pouvoir', 'voir', 'bien', 'savoir', 'falloir', 'femme', 'vouloir', 'devoir', 'an', 'jour', 'france', 'sale', 'mettre', 'prendre', 'français', 'grand', 'vie', 'monde']\n",
            "['faire', 'aller', 'pouvoir', 'voir', 'bien', 'falloir', 'femme', 'jour', 'devoir', 'france', 'savoir', 'vouloir', 'mettre', 'temps', 'an', 'prendre', 'français', 'monde', 'grand', 'passer']\n",
            "['faire', 'aller', 'pouvoir', 'bien', 'voir', 'femme', 'falloir', 'savoir', 'vouloir', 'jour', 'devoir', 'france', 'an', 'mettre', 'prendre', 'temps', 'monde', 'français', 'grand', 'vie']\n",
            "['faire', 'aller', 'pouvoir', 'bien', 'voir', 'femme', 'falloir', 'vouloir', 'savoir', 'devoir', 'jour', 'france', 'prendre', 'an', 'monde', 'grand', 'mettre', 'passer', 'temps', 'vie']\n",
            "['faire', 'aller', 'voir', 'bien', 'pouvoir', 'savoir', 'femme', 'falloir', 'vouloir', 'sale', 'devoir', 'jour', 'grand', 'an', 'vie', 'prendre', 'mettre', 'monde', 'france', 'passer']\n",
            "['pute', 'gros', 'sale', 'fils', 'petit', 'aller', 'faire', 'savoir', 'aime', 'vie', 'grand', 'voir', 'vouloir', 'bien', 'venir', 'an', 'vrai', 'passer', 'falloir', 'prendre']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(topic_coherence)"
      ],
      "metadata": {
        "id": "Ox7ifud-VypI",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fad08cce-6233-4abc-ff97-00a9395a40de"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "-0.04199612969329938\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "topic_diversity"
      ],
      "metadata": {
        "id": "29igyGo-V2Oo",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1a216849-aece-4f71-d664-e2c8502025d1"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.165"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from embedded_topic_model.models.etm import ETM\n",
        "# Training an ETM instance\n",
        "etm_instance = ETM(\n",
        "    vocabulary,\n",
        "    embeddings=embeddings_mapping, # You can pass here the path to a word2vec file or\n",
        "                                   # a KeyedVectors instance\n",
        "    num_topics=8,\n",
        "    epochs=20,\n",
        "    debug_mode=True,\n",
        "    train_embeddings=True, # Optional. If True, ETM will learn word embeddings jointly with\n",
        "                            # topic embeddings. By default, is False. If 'embeddings' argument\n",
        "                            # is being passed, this argument must not be True\n",
        ")\n",
        "\n",
        "etm_instance.fit(train_dataset)"
      ],
      "metadata": {
        "id": "7cDzudZrU2lE",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ef353c21-615a-4ac7-8e1c-9d1dfed0c4ca"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Topics before training: [['aller', 'femme', 'jour', 'voir', 'gros', 'vrai', 'sale', 'bien', 'fils', 'grand'], ['jour', 'sale', 'temps', 'bien', 'chose', 'grand', 'pouvoir', 'pute', 'vrai', 'voir'], ['monde', 'devoir', 'vie', 'français', 'prendre', 'mettre', 'vouloir', 'grand', 'taire', 'aime'], ['croire', 'pouvoir', 'petit', 'jour', 'aller', 'voir', 'gros', 'chose', 'faire', 'mal'], ['falloir', 'savoir', 'gros', 'france', 'aller', 'grand', 'taire', 'prendre', 'passer', 'devoir'], ['passer', 'mettre', 'grand', 'vrai', 'savoir', 'devoir', 'petit', 'faire', 'sale', 'jour'], ['voir', 'devoir', 'pute', 'croire', 'femme', 'gros', 'petit', 'passer', 'france', 'chose'], ['france', 'passer', 'gros', 'mettre', 'devoir', 'faire', 'venir', 'petit', 'temps', 'jour']]\n",
            "Epoch 1 - Learning Rate: 0.005 - KL theta: 0.07 - Rec loss: 5.89 - NELBO: 5.96\n",
            "Epoch 2 - Learning Rate: 0.005 - KL theta: 0.0 - Rec loss: 5.81 - NELBO: 5.81\n",
            "Epoch 3 - Learning Rate: 0.005 - KL theta: 0.0 - Rec loss: 5.82 - NELBO: 5.82\n",
            "Epoch 4 - Learning Rate: 0.005 - KL theta: 0.0 - Rec loss: 5.82 - NELBO: 5.82\n",
            "Epoch 5 - Learning Rate: 0.005 - KL theta: 0.0 - Rec loss: 5.81 - NELBO: 5.81\n",
            "Epoch 6 - Learning Rate: 0.005 - KL theta: 0.0 - Rec loss: 5.82 - NELBO: 5.82\n",
            "Epoch 7 - Learning Rate: 0.005 - KL theta: 0.01 - Rec loss: 5.81 - NELBO: 5.82\n",
            "Epoch 8 - Learning Rate: 0.005 - KL theta: 0.01 - Rec loss: 5.81 - NELBO: 5.82\n",
            "Epoch 9 - Learning Rate: 0.005 - KL theta: 0.0 - Rec loss: 5.81 - NELBO: 5.81\n",
            "Epoch 10 - Learning Rate: 0.005 - KL theta: 0.01 - Rec loss: 5.8 - NELBO: 5.81\n",
            "Topics: [['faire', 'aller', 'voir', 'bien', 'pouvoir', 'sale', 'femme', 'falloir', 'vouloir', 'savoir'], ['faire', 'aller', 'pouvoir', 'voir', 'bien', 'sale', 'vouloir', 'falloir', 'femme', 'savoir'], ['faire', 'aller', 'voir', 'bien', 'pouvoir', 'sale', 'vouloir', 'femme', 'devoir', 'falloir'], ['faire', 'aller', 'voir', 'pouvoir', 'bien', 'sale', 'vouloir', 'falloir', 'femme', 'savoir'], ['faire', 'aller', 'pouvoir', 'voir', 'bien', 'vouloir', 'savoir', 'sale', 'devoir', 'femme'], ['faire', 'aller', 'bien', 'voir', 'pouvoir', 'sale', 'femme', 'falloir', 'vouloir', 'devoir'], ['faire', 'aller', 'voir', 'pouvoir', 'bien', 'vouloir', 'savoir', 'devoir', 'sale', 'femme'], ['pute', 'fils', 'gros', 'france', 'français', 'petit', 'faire', 'aller', 'monde', 'mettre']]\n",
            "Epoch 11 - Learning Rate: 0.005 - KL theta: 0.03 - Rec loss: 5.79 - NELBO: 5.82\n",
            "Epoch 12 - Learning Rate: 0.005 - KL theta: 0.04 - Rec loss: 5.78 - NELBO: 5.82\n",
            "Epoch 13 - Learning Rate: 0.005 - KL theta: 0.04 - Rec loss: 5.77 - NELBO: 5.81\n",
            "Epoch 14 - Learning Rate: 0.005 - KL theta: 0.04 - Rec loss: 5.76 - NELBO: 5.8\n",
            "Epoch 15 - Learning Rate: 0.005 - KL theta: 0.05 - Rec loss: 5.75 - NELBO: 5.8\n",
            "Epoch 16 - Learning Rate: 0.005 - KL theta: 0.05 - Rec loss: 5.76 - NELBO: 5.81\n",
            "Epoch 17 - Learning Rate: 0.005 - KL theta: 0.05 - Rec loss: 5.76 - NELBO: 5.81\n",
            "Epoch 18 - Learning Rate: 0.005 - KL theta: 0.05 - Rec loss: 5.75 - NELBO: 5.8\n",
            "Epoch 19 - Learning Rate: 0.005 - KL theta: 0.05 - Rec loss: 5.75 - NELBO: 5.8\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<embedded_topic_model.models.etm.ETM at 0x7f3ff7345a50>"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "topics = etm_instance.get_topics(20)\n",
        "topic_coherence = etm_instance.get_topic_coherence()\n",
        "topic_diversity = etm_instance.get_topic_diversity()"
      ],
      "metadata": {
        "id": "cEtCfnlbWDP9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "43451941-1277-476b-ad6d-4771d005ecc3"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CPU times: user 1min 33s, sys: 136 ms, total: 1min 33s\n",
            "Wall time: 1min 34s\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for i in range(8): print(topics[i])"
      ],
      "metadata": {
        "id": "1nJw8hM4V76x",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "33f70649-c69a-4ae0-dc69-f2e40c887979"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['faire', 'aller', 'pouvoir', 'bien', 'voir', 'falloir', 'femme', 'savoir', 'vouloir', 'devoir', 'jour', 'france', 'monde', 'mettre', 'sale', 'an', 'grand', 'prendre', 'passer', 'vie']\n",
            "['faire', 'aller', 'pouvoir', 'voir', 'bien', 'falloir', 'savoir', 'femme', 'vouloir', 'devoir', 'france', 'jour', 'mettre', 'sale', 'an', 'prendre', 'grand', 'vie', 'français', 'monde']\n",
            "['faire', 'aller', 'pouvoir', 'voir', 'bien', 'savoir', 'falloir', 'femme', 'vouloir', 'devoir', 'an', 'jour', 'france', 'sale', 'mettre', 'prendre', 'français', 'grand', 'vie', 'monde']\n",
            "['faire', 'aller', 'pouvoir', 'voir', 'bien', 'falloir', 'femme', 'jour', 'devoir', 'france', 'savoir', 'vouloir', 'mettre', 'temps', 'an', 'prendre', 'français', 'monde', 'grand', 'passer']\n",
            "['faire', 'aller', 'pouvoir', 'bien', 'voir', 'femme', 'falloir', 'savoir', 'vouloir', 'jour', 'devoir', 'france', 'an', 'mettre', 'prendre', 'temps', 'monde', 'français', 'grand', 'vie']\n",
            "['faire', 'aller', 'pouvoir', 'bien', 'voir', 'femme', 'falloir', 'vouloir', 'savoir', 'devoir', 'jour', 'france', 'prendre', 'an', 'monde', 'grand', 'mettre', 'passer', 'temps', 'vie']\n",
            "['faire', 'aller', 'voir', 'bien', 'pouvoir', 'savoir', 'femme', 'falloir', 'vouloir', 'sale', 'devoir', 'jour', 'grand', 'an', 'vie', 'prendre', 'mettre', 'monde', 'france', 'passer']\n",
            "['pute', 'gros', 'sale', 'fils', 'petit', 'aller', 'faire', 'savoir', 'aime', 'vie', 'grand', 'voir', 'vouloir', 'bien', 'venir', 'an', 'vrai', 'passer', 'falloir', 'prendre']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Training an ETM instance\n",
        "etm_instance = ETM(\n",
        "    vocabulary,\n",
        "    embeddings= '/content/drive/MyDrive/Colab Notebooks/frwiki_20180420_100d.txt', # You can pass here the path to a word2vec file or\n",
        "                                   # a KeyedVectors instance\n",
        "    num_topics=8,\n",
        "    epochs=20,\n",
        "    debug_mode=True,\n",
        "    train_embeddings=False, # Optional. If True, ETM will learn word embeddings jointly with\n",
        "                            # topic embeddings. By default, is False. If 'embeddings' argument\n",
        "                            # is being passed, this argument must not be True\n",
        ")\n",
        "\n",
        "etm_instance.fit(train_dataset)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 409
        },
        "id": "_2Pc0qT49ReL",
        "outputId": "743198cf-1728-4cff-eb75-f473a20ee507"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Reading embeddings from word2vec file...\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-27-d7242daf7210>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m20\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0mdebug_mode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m     \u001b[0mtrain_embeddings\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;31m# Optional. If True, ETM will learn word embeddings jointly with\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m                             \u001b[0;31m# topic embeddings. By default, is False. If 'embeddings' argument\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m                             \u001b[0;31m# is being passed, this argument must not be True\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/embedded_topic_model/models/etm.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, vocabulary, embeddings, use_c_format_w2vec, model_path, batch_size, num_topics, rho_size, emb_size, t_hidden_size, theta_act, train_embeddings, lr, lr_factor, epochs, optimizer_type, seed, enc_drop, clip, nonmono, wdecay, anneal_lr, bow_norm, num_words, log_interval, visualize_every, eval_batch_size, eval_perplexity, debug_mode)\u001b[0m\n\u001b[1;32m    112\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    113\u001b[0m         self.embeddings = None if train_embeddings else self._initialize_embeddings(\n\u001b[0;32m--> 114\u001b[0;31m             embeddings, use_c_format_w2vec=use_c_format_w2vec)\n\u001b[0m\u001b[1;32m    115\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    116\u001b[0m         self.model = Model(\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/embedded_topic_model/models/etm.py\u001b[0m in \u001b[0;36m_initialize_embeddings\u001b[0;34m(self, embeddings, use_c_format_w2vec)\u001b[0m\n\u001b[1;32m    171\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdebug_mode\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    172\u001b[0m                 \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Reading embeddings from word2vec file...'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 173\u001b[0;31m             \u001b[0mvectors\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mKeyedVectors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0membeddings\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmmap\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'r'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    174\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    175\u001b[0m         \u001b[0mmodel_embeddings\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvocabulary_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0memb_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/gensim/models/keyedvectors.py\u001b[0m in \u001b[0;36mload\u001b[0;34m(cls, fname_or_handle, **kwargs)\u001b[0m\n\u001b[1;32m   1551\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mclassmethod\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1552\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcls\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfname_or_handle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1553\u001b[0;31m         \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mWordEmbeddingsKeyedVectors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcls\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfname_or_handle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1554\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mFastTextKeyedVectors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1555\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'compatible_hash'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/gensim/models/keyedvectors.py\u001b[0m in \u001b[0;36mload\u001b[0;34m(cls, fname_or_handle, **kwargs)\u001b[0m\n\u001b[1;32m    226\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mclassmethod\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    227\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcls\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfname_or_handle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 228\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mBaseKeyedVectors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcls\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfname_or_handle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    229\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    230\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0msimilarity\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mentity1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mentity2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/gensim/utils.py\u001b[0m in \u001b[0;36mload\u001b[0;34m(cls, fname, mmap)\u001b[0m\n\u001b[1;32m    433\u001b[0m         \u001b[0mcompress\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msubname\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mSaveLoad\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_adapt_by_suffix\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    434\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 435\u001b[0;31m         \u001b[0mobj\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0munpickle\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    436\u001b[0m         \u001b[0mobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_load_specials\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmmap\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcompress\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msubname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    437\u001b[0m         \u001b[0mlogger\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"loaded %s\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/gensim/utils.py\u001b[0m in \u001b[0;36munpickle\u001b[0;34m(fname)\u001b[0m\n\u001b[1;32m   1393\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1394\u001b[0m     \"\"\"\n\u001b[0;32m-> 1395\u001b[0;31m     \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'rb'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1396\u001b[0m         \u001b[0;31m# Because of loading from S3 load can't be used (missing readline in smart_open)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1397\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0msys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mversion_info\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/smart_open/smart_open_lib.py\u001b[0m in \u001b[0;36mopen\u001b[0;34m(uri, mode, buffering, encoding, errors, newline, closefd, opener, ignore_ext, compression, transport_params)\u001b[0m\n\u001b[1;32m    193\u001b[0m         \u001b[0mencoding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mencoding\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    194\u001b[0m         \u001b[0merrors\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0merrors\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 195\u001b[0;31m         \u001b[0mnewline\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnewline\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    196\u001b[0m     )\n\u001b[1;32m    197\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfobj\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/smart_open/smart_open_lib.py\u001b[0m in \u001b[0;36m_shortcut_open\u001b[0;34m(uri, mode, compression, buffering, encoding, errors, newline)\u001b[0m\n\u001b[1;32m    359\u001b[0m         \u001b[0mopen_kwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'errors'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    360\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 361\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_builtin_open\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlocal_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbuffering\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbuffering\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mopen_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    362\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    363\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/content/drive/MyDrive/Colab Notebooks/frwiki_20180420_100d.txt'"
          ]
        }
      ]
    }
  ]
}