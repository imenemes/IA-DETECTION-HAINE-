{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "eval_3 variantes.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "sBAVaH1UBHXv"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import glob"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eJZ6V8NGBI7B",
        "outputId": "cff70c33-2a38-4020-da09-eb21c96ee620"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "path_files = r\"/content/drive/MyDrive/\""
      ],
      "metadata": {
        "id": "5bK_XzqVBb36"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Récupérer les fichiers d'outliers**"
      ],
      "metadata": {
        "id": "5o4aXvVaofO7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# récupérer les clusters\n",
        "# glob aide à faire un trie par regex afin d'en choisir les fichiers nettoyés\n",
        "list_outliers_minstp= glob.glob(f\"{path_files}minstp/*\")"
      ],
      "metadata": {
        "id": "1VOD3vnSqd1z"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "list_outliers_lem= glob.glob(f\"{path_files}lem/*\")"
      ],
      "metadata": {
        "id": "VS0aGLqEL5wa"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "list_outliers_std= glob.glob(f\"{path_files}std/*\")"
      ],
      "metadata": {
        "id": "qhLaBqx-MKG8"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "\n",
        "def extr_num(string):\n",
        "    num = re.search(\"([0-9]+)\", string)\n",
        "    return int(num.group(1)) if num else -1"
      ],
      "metadata": {
        "id": "pbn1v-bQsqlM"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def make_liste(liste):\n",
        "  liste_out=[]\n",
        "  liste.sort(key=extr_num)\n",
        "  for file in liste:\n",
        "    liste_out.append(glob.glob(file+'/outliers*'))\n",
        "  return liste_out"
      ],
      "metadata": {
        "id": "_jUKX3tQdBpY"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "liste_files_minstp=make_liste(list_outliers_minstp)"
      ],
      "metadata": {
        "id": "rxwqU_Kquz0C"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "liste_files_lem=make_liste(list_outliers_lem)"
      ],
      "metadata": {
        "id": "x6CP45HwMZen"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "liste_files_std=make_liste(list_outliers_std)"
      ],
      "metadata": {
        "id": "Fpq_L_1MdgFo"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Fonction de lecture de fichiers**"
      ],
      "metadata": {
        "id": "pIhHKjgEgqxt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def extr_num2(string):\n",
        "    num = re.search(\"outliers([0-9]+)\", string)\n",
        "    return int(num.group(1)) if num else -1"
      ],
      "metadata": {
        "id": "45gnkrcbDTP3"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def read_cluster(files):\n",
        "  liste=[]\n",
        "  for i,cluster in enumerate(files):\n",
        "    with open(cluster, \"r\") as file:\n",
        "      liste.append(file.readlines())\n",
        "  return liste"
      ],
      "metadata": {
        "id": "CaY0cTlXeCNO"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def matrice(liste):\n",
        "  cluster_km=[]\n",
        "  for file in liste:\n",
        "    file.sort(key=extr_num2)\n",
        "    cluster_km.append(read_cluster(file))\n",
        "  return cluster_km"
      ],
      "metadata": {
        "id": "2Km9sM1XBrTu"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "matrice_outliers_minstp= matrice(liste_files_minstp)"
      ],
      "metadata": {
        "id": "7OjwGyYRCBt6"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "matrice_outliers_lem= matrice(liste_files_lem)"
      ],
      "metadata": {
        "id": "1JERa_jyMwP9"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "matrice_outliers_std= matrice(liste_files_std)"
      ],
      "metadata": {
        "id": "1R-No4D0EKvy"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Fonction de detection de la haine les outliers de chaque cluster**"
      ],
      "metadata": {
        "id": "g61M_af-g47G"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def search_hate_words(mlists, file):\n",
        "    ret = {}\n",
        "    with open(file, \"r\") as f:\n",
        "        kws = f.read().splitlines()\n",
        "    for i, mlist in enumerate(mlists):\n",
        "        n_msg = 0\n",
        "        for msg in mlist:\n",
        "            for kw in kws:\n",
        "                if kw in msg:\n",
        "                    n_msg += 1\n",
        "                    break\n",
        "        if len(mlist)>0:\n",
        "          perc = (n_msg / len(mlist))*100\n",
        "          ret[i] = (n_msg, perc)\n",
        "    return ret"
      ],
      "metadata": {
        "id": "0FhxFFQ-dK2G"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def results(liste):\n",
        "  res=[]\n",
        "  for i in range(len(liste)):\n",
        "    res.append(search_hate_words(liste[i],f\"{path_files}keyword\"))\n",
        "  return res"
      ],
      "metadata": {
        "id": "ClMzkxjRGuKj"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Enregistre un résumé des informations pour chaque cluster\n",
        "def save_clusters_info(n,res,variante,wlists, method):\n",
        "    f = open(path_files+\"outliers_info\"+variante+\".txt\", \"a\")\n",
        "    f.write(\"methode {}\\n\".format(method))\n",
        "    for i, key in enumerate(sorted(res)):\n",
        "      if res[key][1]>10:\n",
        "        f.write(\"cluster {} : {} messages soit {:.2f}%\\n\".format(key, res[key][0],res[key][1]))\n",
        "        f.write(\"Les {} mots les plus fréquents : \".format(n))\n",
        "        for tup in wlists[i][:n]:\n",
        "          f.write(tup[0]+\" \")\n",
        "        f.write('\\n')\n",
        "    f.close()"
      ],
      "metadata": {
        "id": "Gn4Nvti-84HH"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "liste_method=[\"km_25\",\"km_50\",\"km_100\",\"som_100\",\"som_225\",\"som_400\"]"
      ],
      "metadata": {
        "id": "qvOpdingIES9"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def save_info_variante(n,res, variante,wlists,liste):\n",
        "  for i in range(len(res)):\n",
        "    save_clusters_info(n, res[i], variante,wlists[i] ,liste[i])"
      ],
      "metadata": {
        "id": "2kECpE4zBbId"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Création du dictionnaire de mots avec leur occurence\n",
        "def create_wdict(lines):\n",
        "    dico = {}\n",
        "    for msg in lines:\n",
        "        for mot in msg.split():\n",
        "            if mot in dico: \n",
        "                dico[mot] += 1\n",
        "            else:\n",
        "                dico[mot] = 1\n",
        "    return dico"
      ],
      "metadata": {
        "id": "6-8VysdrLn4v"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def create_sorted_wlist(lines):\n",
        "    dico = create_wdict(lines)\n",
        "    # Crée une liste de tuples associant mot et nombre d'occurences\n",
        "    wlist = [(mot, dico[mot]) for mot in dico.keys()]\n",
        "    # Renvoie la liste triée par nombre d'occurences décroissant\n",
        "    return sorted(wlist, key = lambda mot: mot[1], reverse = True)"
      ],
      "metadata": {
        "id": "hBzP9gRiiZnw"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def liste_dic(matrice):\n",
        "  liste_sorted=[[] for _ in range(len(matrice))]\n",
        "  for i in range(len(matrice)):\n",
        "    for n in range(len(matrice[i])):\n",
        "      liste_sorted[i].append(create_sorted_wlist(matrice[i][n]))  \n",
        "  return liste_sorted"
      ],
      "metadata": {
        "id": "LHmVVzvxLa2T"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**1- Cas d'application d'IF  sur les différents clusters de la version min stopword**"
      ],
      "metadata": {
        "id": "H58hjlv_hQgn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "resultats_minstp=results(matrice_outliers_minstp)"
      ],
      "metadata": {
        "id": "V5wiimO1Gbtf"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "srt_dics_minstp=liste_dic(matrice_outliers_minstp)"
      ],
      "metadata": {
        "id": "T5n4_QvPQHOK"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "save_info_variante(20, resultats_minstp,\"res_minstp\",srt_dics_minstp, liste_method)"
      ],
      "metadata": {
        "id": "TZxOem5a_6Pm"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "On remarque que deux clusters se détachent dans la version Km 100 avec des résultats avoisinant les 12% (cluster 85 et 94) , néanmoins une autre phase de clusterisation (SOM ou IF peut être appliqué dessus afin d'affiner la recherche"
      ],
      "metadata": {
        "id": "LqU0oElON5yv"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**2- Cas d'application d'IF  sur les différents clusters de la version avec lemmatisation**\n",
        "___"
      ],
      "metadata": {
        "id": "x4_wlUmrhH0x"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "resultats_lem=results(matrice_outliers_lem)"
      ],
      "metadata": {
        "id": "2EPOwWurNW1L"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "srt_dics_lem=liste_dic(matrice_outliers_lem)"
      ],
      "metadata": {
        "id": "3g_G3GdpecME"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "save_info_variante(20, resultats_lem,\"res_lem\",srt_dics_lem, liste_method)"
      ],
      "metadata": {
        "id": "vx6vSZxSR_LY"
      },
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "On remarque:\n",
        "\n",
        "1.   le cluster 8 version som 100 avec 16% de mots haineux, (cluster homme femme noir)\n",
        "2.   le cluster 30 version km 100 14%,(rasicte , haine , noir, arabe )\n",
        "3.   le cluster 167 version som 400 11% (pute sale raciste)\n",
        "4.   le cluster  156 version som 400 avec 37% (sur un cluster de 100 tweets) (noir , blanc , arabe )\n",
        "5.   beaucoup de clusters vides sur le som 400 (à voir determiner le pourcentage de ces clusters)\n",
        "\n",
        "d'autres cluster dans la version som 400 ont des proportions de mots haineux avoisinant les 10% à l'image du cluster 275, malheureusement il contient 2 message haineux ce qui veut dire que le cluster contient en tout et pour tout 20 messages au plus , les clusters étant éclatés , ils contiennent moins de message que les autres modèles , on se pose la question de la pertinence d'explorer ce genre de cluster , ceci étant dit , une exploration manuelle dudit cluster nous renseignera plus sur son contenu et sa pertinence .\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "__PnsK94OeoT"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "****3- Cas d'application d'IF  sur les différents clusters de la version avec stemming****\n",
        "\n",
        "---\n",
        "\n"
      ],
      "metadata": {
        "id": "ZAXkmmlhoO0o"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "resultats_std=results(matrice_outliers_std)"
      ],
      "metadata": {
        "id": "QITKZmRmeXsm"
      },
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "srt_dics_std=liste_dic(matrice_outliers_std)"
      ],
      "metadata": {
        "id": "4Xz22lk6TFQH"
      },
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "save_info_variante(20, resultats_std,\"res_std\",srt_dics_std, liste_method)"
      ],
      "metadata": {
        "id": "KbAwnBG3TFGw"
      },
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "1.   cluster 69 km100 15% environs (haine , noir rasicte haine)\n",
        "2.   cluster 53 som100 20% environs (grossièrté (pute , sale et gros mots surtout)\n",
        "\n",
        "som 225\n",
        "3.   cluster 116: 11.5% (fake, certains tweets racistes (3 max ) et le cluster contient 26 tweets )\n",
        "\n",
        "som400\n",
        "\n",
        "4.   cluster 349: 23.40% (race arabe , blanc noir, sale pute)\n",
        "5.   cluster 333: 26.92% (arabe blanc)\n",
        "6.   cluster 89: 16.66% (3 messages) (à part 2 tweets contenant le mot chinois rien de particuluer sur ce cluster)\n"
      ],
      "metadata": {
        "id": "laoxyiltfAYI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Nous remarquons que les meilleurs clusters sont donnés par la méthode SOM400 et KM100 et que les meilleures variantes sont la variante MIN et STD"
      ],
      "metadata": {
        "id": "vXGHLwqlt2kp"
      }
    }
  ]
}