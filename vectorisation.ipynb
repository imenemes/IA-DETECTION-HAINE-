{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "vectorisation.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyOrJax44PchyApvqX511Pwk"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd"
      ],
      "metadata": {
        "id": "zvQuBn82dDx7"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mCDFnjrGC46C",
        "outputId": "17b80e6e-2c0d-434a-c80c-ec49bdf2ae20"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df= pd.read_pickle('/content/drive/MyDrive/Data_M/clean_data.txt')"
      ],
      "metadata": {
        "id": "_d74GA_UDGBV"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "sRqwNpZVDofN",
        "outputId": "da485ea0-6843-49e2-e9e7-135729756245"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                       cleaned_tweet\n",
              "0  être avoir culot venir jouer victime méchant g...\n",
              "1  jslalsbd faisce veu dieuj llook effectvuemy ce...\n",
              "2                                             unisex\n",
              "3  meme être fan puma aller vaincre milan ac team...\n",
              "4                       regarde truc audessus savoir"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-57cc83e1-af5c-4c7e-8c33-098ec5c04916\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>cleaned_tweet</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>être avoir culot venir jouer victime méchant g...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>jslalsbd faisce veu dieuj llook effectvuemy ce...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>unisex</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>meme être fan puma aller vaincre milan ac team...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>regarde truc audessus savoir</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-57cc83e1-af5c-4c7e-8c33-098ec5c04916')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-57cc83e1-af5c-4c7e-8c33-098ec5c04916 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-57cc83e1-af5c-4c7e-8c33-098ec5c04916');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "cleaned_tweet=df.cleaned_tweet"
      ],
      "metadata": {
        "id": "40DtpaQSDw5V"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 6 - **Vectorization** (featurization)"
      ],
      "metadata": {
        "id": "_Qhb5lol5tv5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer"
      ],
      "metadata": {
        "id": "TfeHs0u3eqK6"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "A- **Méthode BOW**"
      ],
      "metadata": {
        "id": "JmFgp4Hokl5w"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# définir le tokenizer\n",
        "def tokenizer(text):\n",
        "    return text\n"
      ],
      "metadata": {
        "id": "E0cvzKvyapM6"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "bow_vectorizer = CountVectorizer(analyzer='word',lowercase=False)\n",
        "print('Tweet before vectorization: {}'.format(cleaned_tweet[83]))\n",
        "bow = bow_vectorizer.fit_transform(cleaned_tweet)\n",
        "\n",
        "print('Tweet after vectorization: \\n{}'.format(bow[83]))\n",
        "bow.shape"
      ],
      "metadata": {
        "id": "k9t563yMkstE",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6a5c8667-d6dd-4bc0-c8b8-dcc831cc0935"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Tweet before vectorization: monsieur député attention souffrance peuple iranien démocratie pouvoir apporter paix pays cnri soutenir œuvre obtenir\n",
            "Tweet after vectorization: \n",
            "  (0, 7977)\t1\n",
            "  (0, 701)\t1\n",
            "  (0, 7556)\t1\n",
            "  (0, 6674)\t1\n",
            "  (0, 3269)\t1\n",
            "  (0, 9602)\t1\n",
            "  (0, 7662)\t1\n",
            "  (0, 5268)\t1\n",
            "  (0, 3224)\t1\n",
            "  (0, 503)\t1\n",
            "  (0, 7392)\t1\n",
            "  (0, 1950)\t1\n",
            "  (0, 9630)\t1\n",
            "  (0, 11413)\t1\n",
            "  (0, 7164)\t1\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(5000, 11452)"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "bow_vectorizer.get_feature_names_out()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Nbb6UNFDIlum",
        "outputId": "351e6258-856b-4d01-edc0-178fb3e9b578"
      },
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array(['aaaahhxhsbd', 'aaaamisazerbaidjan', 'abaca', ..., '𝙡𝙚𝙨', '𝙣𝙤𝙪𝙨',\n",
              "       '𝙥𝙖𝙮𝙨'], dtype=object)"
            ]
          },
          "metadata": {},
          "execution_count": 43
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(bow.toarray())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8iuYDuorIq8o",
        "outputId": "414fe41b-3160-4ce6-dcae-8b5d46c79d0f"
      },
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[0 0 0 ... 0 0 0]\n",
            " [0 0 0 ... 0 0 0]\n",
            " [0 0 0 ... 0 0 0]\n",
            " ...\n",
            " [0 0 0 ... 0 0 0]\n",
            " [0 0 0 ... 0 0 0]\n",
            " [0 0 0 ... 0 0 0]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Mots les plus courants et leur nombre respectif\n",
        "def get_most_freq_words(str, n=None):\n",
        "    vect = CountVectorizer().fit(cleaned_tweet)\n",
        "    bag_of_words = vect.transform(cleaned_tweet)\n",
        "    sum_words = bag_of_words.sum(axis=0) \n",
        "    freq = [(word, sum_words[0, idx]) for word, idx in vect.vocabulary_.items()]\n",
        "    freq =sorted(freq, key = lambda x: x[1], reverse=True)\n",
        "    return freq[:n]\n",
        "  \n",
        "get_most_freq_words([ word for tweet in cleaned_tweet for word in tweet],20)"
      ],
      "metadata": {
        "id": "4rItQIlB4QRI",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "47c57ace-491c-436b-cca1-7e9e38eb772c"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('être', 2539),\n",
              " ('avoir', 1727),\n",
              " ('faire', 525),\n",
              " ('aller', 359),\n",
              " ('pouvoir', 239),\n",
              " ('voir', 205),\n",
              " ('bien', 196),\n",
              " ('savoir', 149),\n",
              " ('jour', 136),\n",
              " ('vouloir', 131),\n",
              " ('france', 118),\n",
              " ('falloir', 118),\n",
              " ('devoir', 117),\n",
              " ('gagner', 105),\n",
              " ('amp', 99),\n",
              " ('vie', 98),\n",
              " ('follow', 94),\n",
              " ('prendre', 91),\n",
              " ('venir', 88),\n",
              " ('grand', 88)]"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "J'essaie ici de jouer avec min_df et max_df de countvectorizer , et ça n'a pas l'air de marcher , car les tweets ont bien été nettoyé, de plus cela témoingne d'une grande diversité des mots au sein de notre corpus"
      ],
      "metadata": {
        "id": "iCGLJtfUhdAf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Mots les plus courants et leur nombre respectif\n",
        "def get_most_freq_words(str, n=None):\n",
        "    vect = CountVectorizer(max_df=0.3, min_df=5).fit(cleaned_tweet)\n",
        "    bag_of_words = vect.transform(cleaned_tweet)\n",
        "    sum_words = bag_of_words.sum(axis=0) \n",
        "    freq = [(word, sum_words[0, idx]) for word, idx in vect.vocabulary_.items()]\n",
        "    freq =sorted(freq, key = lambda x: x[1], reverse=True)\n",
        "    return freq[:n]\n",
        "  \n",
        "get_most_freq_words([ word for tweet in cleaned_tweet for word in tweet],20)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "x8u0wCHzgdQ1",
        "outputId": "c39d66f3-e1e0-4dfd-8c81-f732ea5e6229"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('avoir', 1727),\n",
              " ('faire', 525),\n",
              " ('aller', 359),\n",
              " ('pouvoir', 239),\n",
              " ('voir', 205),\n",
              " ('bien', 196),\n",
              " ('savoir', 149),\n",
              " ('jour', 136),\n",
              " ('vouloir', 131),\n",
              " ('france', 118),\n",
              " ('falloir', 118),\n",
              " ('devoir', 117),\n",
              " ('gagner', 105),\n",
              " ('amp', 99),\n",
              " ('vie', 98),\n",
              " ('follow', 94),\n",
              " ('prendre', 91),\n",
              " ('venir', 88),\n",
              " ('grand', 88),\n",
              " ('semaine', 86)]"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "On constate ici que les mots les plus courants avec BOW sont des verbes non conjugés tels que : être, faire, avoir, etc. "
      ],
      "metadata": {
        "id": "7DTqIxmd5Ig7"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "B- **Méthode TFIDF**"
      ],
      "metadata": {
        "id": "hGqwHTyn58F0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#from numpy.lib.function_base import vectorize\n",
        "#utiliser la méthode de Tfidfvectorizer avec:\n",
        "\"\"\" - les stopsword français importés depuis spacy\n",
        "    - le tokenizer définis plus haut\"\"\"\n",
        "vectorizer = TfidfVectorizer(lowercase=False)\n",
        "print('Tweet before vectorization: {}'.format(cleaned_tweet[83]))"
      ],
      "metadata": {
        "id": "smsdUUntlBiY",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6aaf48c4-ea86-43b0-f2e9-ca6f64dfd488"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Tweet before vectorization: monsieur député attention souffrance peuple iranien démocratie pouvoir apporter paix pays cnri soutenir œuvre obtenir\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# transformer les tweets en vecteurs\n",
        "# qui prend en argument les vecteurs de mots de l'ensemble des tweets nettoyés précédemment \n",
        "X = vectorizer.fit_transform(cleaned_tweet)\n",
        "print('Tweet after vectorization: \\n{}'.format(X[83]))\n",
        "\n",
        "#print ((X.todense()))"
      ],
      "metadata": {
        "id": "gidfHw67lY61",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a396ca7a-35f5-4f4f-8d7a-377e77e1b46d"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Tweet after vectorization: \n",
            "  (0, 7164)\t0.26651956770453816\n",
            "  (0, 11413)\t0.2622991202871934\n",
            "  (0, 9630)\t0.21262488304697705\n",
            "  (0, 1950)\t0.31619380494475446\n",
            "  (0, 7392)\t0.28336092004478347\n",
            "  (0, 503)\t0.28336092004478347\n",
            "  (0, 3224)\t0.27130431635697344\n",
            "  (0, 5268)\t0.31619380494475446\n",
            "  (0, 7662)\t0.2286786786768661\n",
            "  (0, 9602)\t0.28336092004478347\n",
            "  (0, 3269)\t0.2491226633388327\n",
            "  (0, 6674)\t0.2491226633388327\n",
            "  (0, 7556)\t0.19257251307930415\n",
            "  (0, 701)\t0.25510861009461533\n",
            "  (0, 7977)\t0.14809160802751328\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "idf=vectorizer.idf_"
      ],
      "metadata": {
        "id": "sQhXl5-rqQcI"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "C- **Word embeding with Spacy**"
      ],
      "metadata": {
        "id": "Eg82e4Yyqj_G"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def my_word_embedding(sentence):\n",
        "    # Tokeniser la phrase\n",
        "    doc = nlp(sentence)\n",
        "    # Retourner le vecteur lié à chaque token\n",
        "    return [(X.vector) for X in doc]\n",
        "\n",
        "#for n, snt in enumerate(s):\n",
        "    #print(n , \":\", my_word_embedding(snt), \"\\n\")\n",
        "\n",
        "    print(X)"
      ],
      "metadata": {
        "id": "rYaA0E7aoRi9"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "D- **Méthode W2Vec**"
      ],
      "metadata": {
        "id": "AUvbGV6_NROn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "data=list(cleaned_tweet)\n",
        "cleaned_tweet_list= [line.split() for line in data]"
      ],
      "metadata": {
        "id": "4xZaDXMLE464"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import gensim\n",
        "\n",
        "\n",
        "#tokenized_tweet = s.apply(lambda x: x.split()) # tokenizing \n",
        "\n",
        "model_w2v = gensim.models.Word2Vec(\n",
        "            cleaned_tweet_list,\n",
        "            size=200, # desired no. of features/independent variables\n",
        "            window=5, # context window size\n",
        "            min_count=2, # Ignores all words with total frequency lower than 2.                                  \n",
        "            sg = 1, # 1 for skip-gram model\n",
        "            hs = 0,\n",
        "            negative = 10, # for negative sampling\n",
        "            workers= 32, # no.of cores\n",
        "            seed = 34\n",
        ") \n"
      ],
      "metadata": {
        "id": "txJlUHR5NQma"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(model_w2v)"
      ],
      "metadata": {
        "id": "wXGVsdYPs_c5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8f71b18b-650f-498f-c9c7-3e556fb65a41"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Word2Vec(vocab=4615, size=200, alpha=0.025)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "words = list(model_w2v.wv.vocab)"
      ],
      "metadata": {
        "id": "gF1ZmwWRtaor"
      },
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Nombre de mots dans le vocabulaire \n",
        "\n",
        "vocab_len = len(model_w2v.wv.vocab)\n",
        "print(vocab_len)"
      ],
      "metadata": {
        "id": "M1vF2EC6R4qR",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "943fc86b-7c7a-4a91-bc99-6ce1c9ee87b0"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "4615\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model_w2v['haine']"
      ],
      "metadata": {
        "id": "0AZVM5rFPjNF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_w2v.wv.most_similar(positive=\"amour\")"
      ],
      "metadata": {
        "id": "E1E-ehOjOpip",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e9214e12-8d5d-409a-bd53-e22fa82d15a1"
      },
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('envier', 0.9998581409454346),\n",
              " ('wsh', 0.9998572468757629),\n",
              " ('réfléchir', 0.999854326248169),\n",
              " ('artiste', 0.9998530149459839),\n",
              " ('contraire', 0.999851644039154),\n",
              " ('type', 0.9998509287834167),\n",
              " ('main', 0.9998493790626526),\n",
              " ('lever', 0.9998488426208496),\n",
              " ('aider', 0.9998481869697571),\n",
              " ('magazine', 0.9998480081558228)]"
            ]
          },
          "metadata": {},
          "execution_count": 41
        }
      ]
    }
  ]
}